{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import undetected_chromedriver as uc\n",
    "import selenium.webdriver.support.expected_conditions as EC\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "# options.add_argument(\"--headless\")\n",
    "\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://groq.com/pricing/\"\n",
    "driver.get(url)\n",
    "\n",
    "try:\n",
    "    accept_button = WebDriverWait(driver, 5).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//*[text()='Accept' or text()='Accept all']\"), )\n",
    "    )\n",
    "    accept_button.click()\n",
    "except:\n",
    "    print(\"No accept button found\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "html = driver.page_source\n",
    "\n",
    "with open(\"temp/page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "screenshot_path = \"temp/screenshot.png\"\n",
    "status = driver.save_screenshot(screenshot_path)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, Comment, Tag\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    initial_size = len(str(soup))\n",
    "\n",
    "    # Remove comments\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Remove unwanted tags completely\n",
    "    unwanted_tags = [\"style\", \"script\", \"font\", \"link\", \"meta\"]\n",
    "    for tag in unwanted_tags:\n",
    "        for element in soup.find_all(tag):\n",
    "            element.decompose()\n",
    "\n",
    "    # Remove nested wrapper tags\n",
    "    def is_wrapper_tag(tag):\n",
    "        children = tag.contents \n",
    "        return (\n",
    "            len(children) == 1 \n",
    "            and isinstance(children[0], Tag)\n",
    "            and not tag.get(\"id\")\n",
    "            and not tag.get(\"class\")\n",
    "        )\n",
    "    for tag in soup.find_all([\"div\", \"span\"]):\n",
    "        if is_wrapper_tag(tag):\n",
    "            tag.replace_with(tag.contents[0])  \n",
    "\n",
    "    # Add counter for class enumeration\n",
    "    class_counter = 0\n",
    "\n",
    "    # Remove all attributes except allowed ones\n",
    "    allowed_attrs = [\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"href\",\n",
    "        \"alt\"\n",
    "    ]\n",
    "\n",
    "    for tag in soup.find_all(True):\n",
    "        attrs = dict(tag.attrs)\n",
    "\n",
    "        for attr in attrs:\n",
    "            if attr == \"class\":\n",
    "                tag[\"c\"] = str(class_counter)\n",
    "                class_counter += 1\n",
    "                del tag[attr]\n",
    "                \n",
    "            elif attr not in allowed_attrs:\n",
    "                del tag[attr]   \n",
    "    \n",
    "    cleaned_html = str(soup)\n",
    "\n",
    "    # Remove multiple spaces and newlines\n",
    "    cleaned_html = \" \".join(cleaned_html.split())\n",
    "\n",
    "    # Remove empty tags\n",
    "    empty_tags_pattern = r\"<[^/>][^>]*>\\s*</[^>]+>\"\n",
    "    cleaned_html = re.sub(empty_tags_pattern, \"\", cleaned_html)\n",
    "\n",
    "    final_size = len(cleaned_html)\n",
    "    print(f\"Size reduced by {100 - (final_size * 100//initial_size)}%\")\n",
    "\n",
    "    return cleaned_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size reduced by 75%\n"
     ]
    }
   ],
   "source": [
    "cleaned_html = cleanup_html(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_formatted_html(html_content, output_file_name):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    formatted_html = soup.prettify()\n",
    "    with open(\"temp/\"+output_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(formatted_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_formatted_html(cleaned_html, \"cleaned_html.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokencost import calculate_prompt_cost, count_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure html cost:  $0.13 Tokens:  53,396\n",
      "Cleaned html cost:  $0.04 Tokens:  14,964\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o\"\n",
    "\n",
    "print(\n",
    "    \"Pure html cost: \", f\"${calculate_prompt_cost(html, model):,.2f}\",\n",
    "    \"Tokens: \", f\"{count_string_tokens(html, model):,}\",\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Cleaned html cost: \", f\"${calculate_prompt_cost(cleaned_html, model):,.2f}\",\n",
    "    \"Tokens: \", f\"{count_string_tokens(cleaned_html, model):,}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
